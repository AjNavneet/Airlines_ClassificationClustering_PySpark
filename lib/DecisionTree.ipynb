{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141207e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyspark library\n",
    "import pyspark\n",
    "\n",
    "# Import spark session library\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467b534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession object\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Decision_Tree_Classification\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d84b50",
   "metadata": {},
   "source": [
    "# Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3bb83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV data into a DataFrame using SparkSession\n",
    "data1 = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\  # Use the first row as column headers\n",
    "                .option(\"inferSchema\", \"true\")\\  # Infer the data types of columns\n",
    "                .load(\"Social_Network_Ads.csv\")  # Load data from the specified CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "919310a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+---------------+---------+\n",
      "| User ID|Gender|Age|EstimatedSalary|Purchased|\n",
      "+--------+------+---+---------------+---------+\n",
      "|15624510|  Male| 19|          19000|        0|\n",
      "|15810944|  Male| 35|          20000|        0|\n",
      "|15668575|Female| 26|          43000|        0|\n",
      "|15603246|Female| 27|          57000|        0|\n",
      "|15804002|  Male| 19|          76000|        0|\n",
      "|15728773|  Male| 27|          58000|        0|\n",
      "|15598044|Female| 27|          84000|        0|\n",
      "|15694829|Female| 32|         150000|        1|\n",
      "|15600575|  Male| 25|          33000|        0|\n",
      "|15727311|Female| 35|          65000|        0|\n",
      "|15570769|Female| 26|          80000|        0|\n",
      "|15606274|Female| 26|          52000|        0|\n",
      "|15746139|  Male| 20|          86000|        0|\n",
      "|15704987|  Male| 32|          18000|        0|\n",
      "|15628972|  Male| 18|          82000|        0|\n",
      "|15697686|  Male| 29|          80000|        0|\n",
      "|15733883|  Male| 47|          25000|        1|\n",
      "|15617482|  Male| 45|          26000|        1|\n",
      "|15704583|  Male| 46|          28000|        1|\n",
      "|15621083|Female| 48|          29000|        1|\n",
      "+--------+------+---+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd03463",
   "metadata": {},
   "source": [
    "# Verctorize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d983c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae6ea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+---------------+---------+---------------+\n",
      "|User ID |Gender|Age|EstimatedSalary|Purchased|features       |\n",
      "+--------+------+---+---------------+---------+---------------+\n",
      "|15624510|Male  |19 |19000          |0        |[19.0,19000.0] |\n",
      "|15810944|Male  |35 |20000          |0        |[35.0,20000.0] |\n",
      "|15668575|Female|26 |43000          |0        |[26.0,43000.0] |\n",
      "|15603246|Female|27 |57000          |0        |[27.0,57000.0] |\n",
      "|15804002|Male  |19 |76000          |0        |[19.0,76000.0] |\n",
      "|15728773|Male  |27 |58000          |0        |[27.0,58000.0] |\n",
      "|15598044|Female|27 |84000          |0        |[27.0,84000.0] |\n",
      "|15694829|Female|32 |150000         |1        |[32.0,150000.0]|\n",
      "|15600575|Male  |25 |33000          |0        |[25.0,33000.0] |\n",
      "|15727311|Female|35 |65000          |0        |[35.0,65000.0] |\n",
      "+--------+------+---+---------------+---------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a VectorAssembler to combine specified input columns into a single feature column\n",
    "vectorizer = VectorAssembler()  \n",
    "\n",
    "# Set the input columns to be assembled into the features column\n",
    "vectorizer.setInputCols([\"Age\", \"EstimatedSalary\"])  \n",
    "\n",
    "# Set the name of the output feature column\n",
    "vectorizer.setOutputCol(\"features\")  \n",
    "\n",
    "# Transform the DataFrame by assembling the specified input columns into the features column\n",
    "data = vectorizer.transform(data1)  \n",
    "\n",
    "# Display the first 10 rows of the transformed DataFrame\n",
    "data.show(10, False)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567235d",
   "metadata": {},
   "source": [
    "# Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "358381af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scaler library\n",
    "from pyspark.ml.feature import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "185fde5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MinMaxScaler to scale the features column\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4890645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+---------------+---------+---------------+--------------------+\n",
      "| User ID|Gender|Age|EstimatedSalary|Purchased|       features|      scaledFeatures|\n",
      "+--------+------+---+---------------+---------+---------------+--------------------+\n",
      "|15624510|  Male| 19|          19000|        0| [19.0,19000.0]|[0.02380952380952...|\n",
      "|15810944|  Male| 35|          20000|        0| [35.0,20000.0]|[0.40476190476190...|\n",
      "|15668575|Female| 26|          43000|        0| [26.0,43000.0]|[0.19047619047619...|\n",
      "|15603246|Female| 27|          57000|        0| [27.0,57000.0]|[0.21428571428571...|\n",
      "|15804002|  Male| 19|          76000|        0| [19.0,76000.0]|[0.02380952380952...|\n",
      "|15728773|  Male| 27|          58000|        0| [27.0,58000.0]|[0.21428571428571...|\n",
      "|15598044|Female| 27|          84000|        0| [27.0,84000.0]|[0.21428571428571...|\n",
      "|15694829|Female| 32|         150000|        1|[32.0,150000.0]|[0.33333333333333...|\n",
      "|15600575|  Male| 25|          33000|        0| [25.0,33000.0]|[0.16666666666666...|\n",
      "|15727311|Female| 35|          65000|        0| [35.0,65000.0]|[0.40476190476190...|\n",
      "|15570769|Female| 26|          80000|        0| [26.0,80000.0]|[0.19047619047619...|\n",
      "|15606274|Female| 26|          52000|        0| [26.0,52000.0]|[0.19047619047619...|\n",
      "|15746139|  Male| 20|          86000|        0| [20.0,86000.0]|[0.04761904761904...|\n",
      "|15704987|  Male| 32|          18000|        0| [32.0,18000.0]|[0.33333333333333...|\n",
      "|15628972|  Male| 18|          82000|        0| [18.0,82000.0]|[0.0,0.4962962962...|\n",
      "|15697686|  Male| 29|          80000|        0| [29.0,80000.0]|[0.26190476190476...|\n",
      "|15733883|  Male| 47|          25000|        1| [47.0,25000.0]|[0.69047619047619...|\n",
      "|15617482|  Male| 45|          26000|        1| [45.0,26000.0]|[0.64285714285714...|\n",
      "|15704583|  Male| 46|          28000|        1| [46.0,28000.0]|[0.66666666666666...|\n",
      "|15621083|Female| 48|          29000|        1| [48.0,29000.0]|[0.71428571428571...|\n",
      "+--------+------+---+---------------+---------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the MinMaxScaler to the data and obtain a scaler model\n",
    "scalerModel = scaler.fit(data)\n",
    "\n",
    "# Transform the data using the fitted scaler model to obtain scaled features\n",
    "scaledData = scalerModel.transform(data)\n",
    "\n",
    "# Display the resulting DataFrame with scaled features\n",
    "scaledData.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cbfdef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(scaledFeatures=DenseVector([0.0238, 0.0296])),\n",
       " Row(scaledFeatures=DenseVector([0.4048, 0.037]))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scaledData.select(\"scaledFeatures\").take(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c8e52",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a19037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules for creating a Spark ML Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20558909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index labels by adding metadata to the 'Purchased' column.\n",
    "# Fit the StringIndexer on the entire dataset to include all labels in the index.\n",
    "labelIndexer = StringIndexer(inputCol=\"Purchased\", outputCol=\"indexedLabel\").fit(scaledData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a68cb5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically identify categorical features and index them.\n",
    "# We specify maxCategories so that features with more than 4 distinct values are treated as continuous.\n",
    "featureIndexer = VectorIndexer(inputCol=\"scaledFeatures\", outputCol=\"indexedFeatures\", maxCategories=4).fit(scaledData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20812873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets with a 70-30 ratio (70% for training, 30% for testing)\n",
    "(trainingData, testData) = scaledData.randomSplit([0.7, 0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d9e6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a DecisionTree model with specified label and features columns\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f73bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain the label indexer, feature indexer, and decision tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30caec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model. This step also runs the label and feature indexers in the specified pipeline.\n",
    "model = pipeline.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e491eb5",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e612fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the trained model on the test data.\n",
    "predictions = model.transform(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aec9972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+\n",
      "|prediction|Purchased|      scaledFeatures|\n",
      "+----------+---------+--------------------+\n",
      "|       0.0|        0|[0.40476190476190...|\n",
      "|       1.0|        1|[0.95238095238095...|\n",
      "|       0.0|        0|[0.40476190476190...|\n",
      "|       1.0|        1|[0.95238095238095...|\n",
      "|       0.0|        0|[0.11904761904761...|\n",
      "+----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select specific columns ('prediction', 'Purchased', 'scaledFeatures') from the predictions DataFrame and display the first 5 rows.\n",
    "predictions.select(\"prediction\", \"Purchased\", \"scaledFeatures\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86b5a9",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbf77b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0869565 \n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute the test accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Evaluate the accuracy of the predictions on the test data\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print the test error, which is the complement of the accuracy\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ffd8544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_eb30250fc606, depth=5, numNodes=31, numClasses=2, numFeatures=2\n"
     ]
    }
   ],
   "source": [
    "# Get the DecisionTree model from the trained pipeline model\n",
    "treeModel = model.stages[2]\n",
    "\n",
    "# Print a summary of the DecisionTree model\n",
    "print(treeModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c00aa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+\n",
      "|Purchased|prediction|count|\n",
      "+---------+----------+-----+\n",
      "|        1|       0.0|    8|\n",
      "|        0|       0.0|   66|\n",
      "|        1|       1.0|   39|\n",
      "|        0|       1.0|    2|\n",
      "+---------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group predictions by 'Purchased' and 'prediction' columns, then count occurrences and display the result.\n",
    "predictions.groupBy('Purchased', 'prediction').count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15a2cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 0.913043 \n"
     ]
    }
   ],
   "source": [
    "# Calculate the elements of the confusion matrix\n",
    "TN = predictions.filter('prediction = 0 AND Purchased = prediction').count()\n",
    "TP = predictions.filter('prediction = 1 AND Purchased = prediction').count()\n",
    "FN = predictions.filter('prediction = 0 AND Purchased = 1').count()\n",
    "FP = predictions.filter('prediction = 1 AND Purchased = 0').count()\n",
    "\n",
    "# Calculate model accuracy as the proportion of correct predictions\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "\n",
    "# Print the model accuracy\n",
    "print(\"Model Accuracy = %g\" % (accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9526e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
